# -*- coding: utf-8 -*-
# ---------------------------------------------------------------------------
# ncTodbf.py
# Created on: 2013-11-21 01:12:52.00000
#   (generated by ArcGIS/ModelBuilder) 
# Description: 
# ---------------------------------------------------------------------------

# Import arcpy module
import arcpy,os,re,time
from arcpy import env
from arcpy.sa import *

#Download NetCDF files - renamed before starting processing (NOT REQUIRED)
# NOTE: The coverage area of precipitation value is smaller than the limari basin
# So the limari Basin was cut ( ensuring that most of the elevation zones were present in the clipped region)
# to the area of the precipitation values
# I will redownload the netcdf files so they cover the entire basin later probably tomorrow and rerun everything
# tomorrow. But I think for now this should be a good estimate of the average precipitation in each zone. 

arcpy.env.overwriteOutput = True
env.workspace = "C:\\Users\\Owner\\Documents\\ArcGIS\\p2010.gdb"
# Local variables:
Variables = "precipitation"
Row_Dimensions = "lat;lon"
ncDir = "C:\\Users\\Owner\\Documents\\ArcGIS\\netcdf\\2010"
netCDF = os.listdir("C:\\Users\\Owner\\Documents\\ArcGIS\\netcdf\\2010")
Output_Table = "temporary"

### convert netCDF to table View 
##for nc in netCDF:
##    if nc.endswith('nc'):
##        #print 'made it'
##        ncpath =  ncDir + '\\' + nc
##        output =arcpy.MakeNetCDFTableView_md(ncpath, Variables,Output_Table, Row_Dimensions, "", "BY_VALUE")
##        #print "Finished Making table"
##        # When naming table make sure to use a name that is withouth an extension hence
##        # nc[0:5] = ##_## and not nc = ##_##.nc
##        arcpy.CopyRows_management(output,'table_'+nc[0:5])
##        print "Finished saving table " + nc[0:5]
##print " Finished converting for 2011"
##
###  Takes all table views created join to one main table and delete "extra' table views 
###  Converts to coordinates in main table to UTM coordinates in order to overlay on Limari shapefile
###  Original Coordinates in DD_2 (Degree Days). 
##
##DBFs=arcpy.ListTables()
##maintable = DBFs[0]
##for dbf in DBFs[1:]:    
##    arcpy.JoinField_management(maintable,'OBJECTID',dbf,'OBJECTID','precipitation')
##    arcpy.Delete_management(dbf)
##    print "Joined " + dbf 
##print "Converting DD_2 to UTM_Zones"
##utm = maintable+'_utm' # feature class that will be save in the workspace 
##arcpy.ConvertCoordinateNotation_management(maintable,utm,'lon','lat','DD_2','UTM_ZONES')        
##print 'Finished Joining 2011'
##
###clip to basin
##limari = 'C:/Users/Owner/Documents/ArcGIS/LimariElevationZones/LimariBasin.shp'
##clippedPath = ncDir + '/'+ 'utm_YR_limari.shp'
##arcpy.Clip_analysis(utm,limari,clippedPath)
##print 'Finished Cliping 2011'




# Take discrete precipitation values and using kriging technique get continuos precipitation values for the entire LimariBasin
# Clip and then perform zonal stats

arcpy.CheckOutExtension('spatial')
limariElev = 'C:/Users/Owner/Documents/ArcGIS/LimariElevationZones/LimariElevZoneNEW.tif'
##utm = ncDir + '/'+'utm_2010_limari.shp'
utm = env.workspace + '/'+ 'table_05_01_utm'
# Limari Zones 
cut_limariElev = ncDir[:-5]+'\\'+'krig_limari'
limariRaster = Raster(cut_limariElev)
# Fields of the Composite Feature Class Created in the Prior Steps
fields=arcpy.ListFields(utm)
missing = []
if fields :
    print " Found files for table " + utm[-17:]
    utm_zonal = 'utm_p2010_zonal'
    ztemp = 'p2010_ztemp'
##    X-Minimum, Y-Minimum, X-Maximum, Y-Maximum.
    clip_rectangle = '246285.712872  6579008.610253 369454.091317 6641030.485769'
    for zfield in fields :
            if re.search('precip',zfield.name):
                    lagsize = '0.003'
                    semivariogramModel = 'Gaussian'
                    try:
                        KrigingOrdinary = KrigingModelOrdinary(semivariogramModel,lagsize)
                        krig = Kriging(utm, zfield.name, KrigingOrdinary,0.003,RadiusVariable(12))
                        print 'Kriging successful'
                        #env.workspace = ncDir
                        #arcpy.Clip_management(limariElev,clip_rectangle,cut_limariElev)
                        #print 'Clipping successful'
                          
                        if zfield.name == fields[4].name:
                                # First time perform clipping and after that use the same clipp file
                                ZonalStatisticsAsTable(limariRaster,'VALUE', krig, utm_zonal,'DATA','MEAN')
                                arcpy.DeleteField_management (utm_zonal, ["Count","AREA"])
                                print 'Made first table'
                        else:
                                time.sleep(0.5)
                                ZonalStatisticsAsTable(limariRaster,'VALUE', krig, ztemp,'DATA','MEAN')
                                arcpy.DeleteField_management (ztemp, ["Count","AREA"])
                                arcpy.JoinField_management(utm_zonal,"MEAN",ztemp,"MEAN")
                                arcpy.DeleteIdentical_management(utm_zonal,"VALUE")
                                print 'Joining Successful'
                    except:
                        missing.append(fields.index(zfield))
### missing206=[4, 23, 55, 59, 60, 69, 73, 74, 81, 86, 106, 110, 123, 124, 139, 144, 145, 156, 159, 160, 162, 174, 181, 186, 192, 195, 198, 201, 205, 219, 220, 221, 222, 226, 227, 232, 235, 237, 238, 239, 240, 242, 243, 246, 247]                        
##numpy_krig = arcpy.da.TableToNumPyArray(utm_zonal,"*",null_value = 0)
### Add the empy spaces for the days where kriging could not be applied :
##for day in missing:
##    numpy_krig  =[]
##    >>> a = np.array([[1, 1], [2, 2], [3, 3]])
##>>> a
##array([[1, 1],
##       [2, 2],
##       [3, 3]])
##>>> np.insert(a, 1, 5)
##array([1, 5, 1, 2, 2, 3, 3])
##>>> np.insert(a, 1, 5, axis=1)
##array([[1, 5, 1],
##       [2, 5, 2],
##       [3, 5, 3]])
                            
print "Finished Kriging & Zonal Stats"
arcpy.Delete_management(ztemp)
arcpy.CheckInExtension('spatial')
